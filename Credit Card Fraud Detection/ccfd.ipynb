{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3276f746-56e8-45da-b42c-0e7ae51074fb",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['Class'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 18\u001b[0m\n\u001b[0;32m     15\u001b[0m data \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mUsers\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mADMIN\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mData Analytics Projects\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mCredit Card Fraud Detection\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mcreditcard.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;66;03m#('creditcard.csv')\u001b[39;00m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# Separate features and labels\u001b[39;00m\n\u001b[1;32m---> 18\u001b[0m X \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mdrop(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mClass\u001b[39m\u001b[38;5;124m'\u001b[39m, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     19\u001b[0m y \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mClass\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m# Split the data into training and testing sets\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\new_env\\Lib\\site-packages\\pandas\\core\\frame.py:5568\u001b[0m, in \u001b[0;36mDataFrame.drop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   5420\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdrop\u001b[39m(\n\u001b[0;32m   5421\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   5422\u001b[0m     labels: IndexLabel \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   5429\u001b[0m     errors: IgnoreRaise \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   5430\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   5431\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   5432\u001b[0m \u001b[38;5;124;03m    Drop specified labels from rows or columns.\u001b[39;00m\n\u001b[0;32m   5433\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   5566\u001b[0m \u001b[38;5;124;03m            weight  1.0     0.8\u001b[39;00m\n\u001b[0;32m   5567\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 5568\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mdrop(\n\u001b[0;32m   5569\u001b[0m         labels\u001b[38;5;241m=\u001b[39mlabels,\n\u001b[0;32m   5570\u001b[0m         axis\u001b[38;5;241m=\u001b[39maxis,\n\u001b[0;32m   5571\u001b[0m         index\u001b[38;5;241m=\u001b[39mindex,\n\u001b[0;32m   5572\u001b[0m         columns\u001b[38;5;241m=\u001b[39mcolumns,\n\u001b[0;32m   5573\u001b[0m         level\u001b[38;5;241m=\u001b[39mlevel,\n\u001b[0;32m   5574\u001b[0m         inplace\u001b[38;5;241m=\u001b[39minplace,\n\u001b[0;32m   5575\u001b[0m         errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[0;32m   5576\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\new_env\\Lib\\site-packages\\pandas\\core\\generic.py:4785\u001b[0m, in \u001b[0;36mNDFrame.drop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   4783\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m axis, labels \u001b[38;5;129;01min\u001b[39;00m axes\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m   4784\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m labels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 4785\u001b[0m         obj \u001b[38;5;241m=\u001b[39m obj\u001b[38;5;241m.\u001b[39m_drop_axis(labels, axis, level\u001b[38;5;241m=\u001b[39mlevel, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[0;32m   4787\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inplace:\n\u001b[0;32m   4788\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_inplace(obj)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\new_env\\Lib\\site-packages\\pandas\\core\\generic.py:4827\u001b[0m, in \u001b[0;36mNDFrame._drop_axis\u001b[1;34m(self, labels, axis, level, errors, only_slice)\u001b[0m\n\u001b[0;32m   4825\u001b[0m         new_axis \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mdrop(labels, level\u001b[38;5;241m=\u001b[39mlevel, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[0;32m   4826\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 4827\u001b[0m         new_axis \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mdrop(labels, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[0;32m   4828\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mget_indexer(new_axis)\n\u001b[0;32m   4830\u001b[0m \u001b[38;5;66;03m# Case for non-unique axis\u001b[39;00m\n\u001b[0;32m   4831\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\new_env\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:7070\u001b[0m, in \u001b[0;36mIndex.drop\u001b[1;34m(self, labels, errors)\u001b[0m\n\u001b[0;32m   7068\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mask\u001b[38;5;241m.\u001b[39many():\n\u001b[0;32m   7069\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m errors \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m-> 7070\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlabels[mask]\u001b[38;5;241m.\u001b[39mtolist()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not found in axis\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   7071\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m indexer[\u001b[38;5;241m~\u001b[39mmask]\n\u001b[0;32m   7072\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdelete(indexer)\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['Class'] not found in axis\""
     ]
    }
   ],
   "source": [
    "#1. Data Collection and Preprocessing\n",
    "\"\"\"\n",
    "1. Data Collection and Preprocessing\n",
    "Start by loading the dataset and preprocessing it. For demonstration purposes, \n",
    "let's assume you're using a dataset like the one from Kaggle's Credit Card Fraud Detection dataset.\n",
    "\"\"\"\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Load the dataset\n",
    "# Load the data\n",
    "    #data = load_data(r\"C:\\Users\\ADMIN\\Data Analytics Projects\\Student Perfomance Prediction Project\\student_data.csv\")\n",
    "\n",
    "data = pd.read_csv(r\"C:\\Users\\ADMIN\\Data Analytics Projects\\Credit Card Fraud Detection\\creditcard.csv\")#('creditcard.csv')\n",
    "\n",
    "# Separate features and labels\n",
    "X = data.drop('Class', axis=1)\n",
    "y = data['Class']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "\"\"\"2. Exploratory Data Analysis (EDA)\n",
    "Performing EDA to understand the data distribution, correlations, and identifying any anomalies.\"\"\"\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot class distribution\n",
    "sns.countplot(y)\n",
    "plt.title('Class Distribution')\n",
    "plt.show()\n",
    "\n",
    "# Plotting some features\n",
    "sns.pairplot(data[['V1', 'V2', 'V3', 'Class']], hue='Class')\n",
    "plt.show() \n",
    "\n",
    "\n",
    "\"\"\"3. Feature Engineering\n",
    "Enhancing features to improve model performance.\"\"\"\n",
    "\n",
    "# Example of creating new features or modifying existing ones\n",
    "data['V1_V2_ratio'] = data['V1'] / (data['V2'] + 1e-6)  # Avoid division by zero\n",
    "# You can add more such features based on domain knowledge\n",
    "\n",
    "\"\"\"\n",
    "4. Model Development\n",
    "Using Logistic Regression as the base model.\n",
    "\"\"\"\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Initialize and train the model\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "5. Model Evaluation and Tuning\n",
    "Evaluating the model's performance and tuning hyperparameters.\n",
    "\"\"\"\n",
    "\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "class_report = classification_report(y_test, y_pred)\n",
    "\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print('Confusion Matrix:')\n",
    "print(conf_matrix)\n",
    "print('Classification Report:')\n",
    "print(class_report)\n",
    "\n",
    "\n",
    "\"\"\"6. Addressing Class Imbalance\n",
    "Using under-sampling and ensemble techniques.\"\"\"\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.ensemble import BalancedBaggingClassifier\n",
    "\n",
    "# Under-sampling\n",
    "rus = RandomUnderSampler(random_state=42)\n",
    "X_res, y_res = rus.fit_resample(X_train, y_train)\n",
    "\n",
    "# Ensemble technique\n",
    "bbc = BalancedBaggingClassifier(base_estimator=LogisticRegression(max_iter=1000),\n",
    "                                sampling_strategy='auto',\n",
    "                                replacement=False,\n",
    "                                random_state=42)\n",
    "bbc.fit(X_res, y_res)\n",
    "\n",
    "# Evaluate ensemble model\n",
    "y_pred_ensemble = bbc.predict(X_test)\n",
    "accuracy_ensemble = accuracy_score(y_test, y_pred_ensemble)\n",
    "conf_matrix_ensemble = confusion_matrix(y_test, y_pred_ensemble)\n",
    "class_report_ensemble = classification_report(y_test, y_pred_ensemble)\n",
    "\n",
    "print(f'Ensemble Model Accuracy: {accuracy_ensemble}')\n",
    "print('Ensemble Model Confusion Matrix:')\n",
    "print(conf_matrix_ensemble)\n",
    "print('Ensemble Model Classification Report:')\n",
    "print(class_report_ensemble)\n",
    "\n",
    "\n",
    "\"\"\"7. Optimization and Deployment\n",
    "Further optimizing model efficiency and preparing for deployment.\"\"\"\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Hyperparameter tuning\n",
    "param_grid = {\n",
    "    'base_estimator__C': [0.01, 0.1, 1, 10, 100],\n",
    "    'n_estimators': [10, 50, 100]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(estimator=bbc, param_grid=param_grid, scoring='accuracy', cv=5)\n",
    "grid_search.fit(X_res, y_res)\n",
    "\n",
    "# Best parameters and best score\n",
    "best_params = grid_search.best_params_\n",
    "best_score = grid_search.best_score_\n",
    "\n",
    "print(f'Best Parameters: {best_params}')\n",
    "print(f'Best Score: {best_score}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "79397882-1b94-4598-bd1f-674de858c7a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.99655\n",
      "Confusion Matrix:\n",
      "[[19373    33]\n",
      " [   36   558]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     19406\n",
      "           1       0.94      0.94      0.94       594\n",
      "\n",
      "    accuracy                           1.00     20000\n",
      "   macro avg       0.97      0.97      0.97     20000\n",
      "weighted avg       1.00      1.00      1.00     20000\n",
      "\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "BalancedBaggingClassifier.__init__() got an unexpected keyword argument 'base_estimator'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 66\u001b[0m\n\u001b[0;32m     63\u001b[0m X_res, y_res \u001b[38;5;241m=\u001b[39m rus\u001b[38;5;241m.\u001b[39mfit_resample(X_train, y_train)\n\u001b[0;32m     65\u001b[0m \u001b[38;5;66;03m# Ensemble technique\u001b[39;00m\n\u001b[1;32m---> 66\u001b[0m bbc \u001b[38;5;241m=\u001b[39m BalancedBaggingClassifier(base_estimator\u001b[38;5;241m=\u001b[39mLogisticRegression(max_iter\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1000\u001b[39m),\n\u001b[0;32m     67\u001b[0m                                 sampling_strategy\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     68\u001b[0m                                 replacement\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m     69\u001b[0m                                 random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[0;32m     70\u001b[0m bbc_pipeline \u001b[38;5;241m=\u001b[39m Pipeline(steps\u001b[38;5;241m=\u001b[39m[(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpreprocessor\u001b[39m\u001b[38;5;124m'\u001b[39m, preprocessor),\n\u001b[0;32m     71\u001b[0m                                (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mensemble\u001b[39m\u001b[38;5;124m'\u001b[39m, bbc)])\n\u001b[0;32m     73\u001b[0m bbc_pipeline\u001b[38;5;241m.\u001b[39mfit(X_res, y_res)\n",
      "\u001b[1;31mTypeError\u001b[0m: BalancedBaggingClassifier.__init__() got an unexpected keyword argument 'base_estimator'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.ensemble import BalancedBaggingClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv('prev_creditcard.csv')\n",
    "\n",
    "# Separate features and labels\n",
    "X = data.drop('is_fraud', axis=1)\n",
    "y = data['is_fraud']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Categorical features\n",
    "categorical_features = ['gender', 'transaction_location', 'transaction_type', 'card_present', 'repeat_customer', 'merchant_category', 'previous_fraud', 'device_type', 'internet_access']\n",
    "\n",
    "# Numeric features\n",
    "numeric_features = ['transaction_time', 'transaction_amount', 'age', 'account_balance', 'amount_time_interaction', 'age_balance_interaction']\n",
    "\n",
    "# Preprocessing pipeline for numeric and categorical features\n",
    "numeric_transformer = StandardScaler()\n",
    "categorical_transformer = OneHotEncoder()\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ])\n",
    "\n",
    "# Model pipeline\n",
    "model_pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                                 ('classifier', LogisticRegression(max_iter=1000))])\n",
    "\n",
    "# Train the model\n",
    "model_pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model_pipeline.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "class_report = classification_report(y_test, y_pred)\n",
    "\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print('Confusion Matrix:')\n",
    "print(conf_matrix)\n",
    "print('Classification Report:')\n",
    "print(class_report)\n",
    "\n",
    "# Under-sampling\n",
    "rus = RandomUnderSampler(random_state=42)\n",
    "X_res, y_res = rus.fit_resample(X_train, y_train)\n",
    "\n",
    "# Ensemble technique\n",
    "bbc = BalancedBaggingClassifier(base_estimator=LogisticRegression(max_iter=1000),\n",
    "                                sampling_strategy='auto',\n",
    "                                replacement=False,\n",
    "                                random_state=42)\n",
    "bbc_pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                               ('ensemble', bbc)])\n",
    "\n",
    "bbc_pipeline.fit(X_res, y_res)\n",
    "\n",
    "# Evaluate ensemble model\n",
    "y_pred_ensemble = bbc_pipeline.predict(X_test)\n",
    "accuracy_ensemble = accuracy_score(y_test, y_pred_ensemble)\n",
    "conf_matrix_ensemble = confusion_matrix(y_test, y_pred_ensemble)\n",
    "class_report_ensemble = classification_report(y_test, y_pred_ensemble)\n",
    "\n",
    "print(f'Ensemble Model Accuracy: {accuracy_ensemble}')\n",
    "print('Ensemble Model Confusion Matrix:')\n",
    "print(conf_matrix_ensemble)\n",
    "print('Ensemble Model Classification Report:')\n",
    "print(class_report_ensemble)\n",
    "\n",
    "# Hyperparameter tuning\n",
    "param_grid = {\n",
    "    'ensemble__base_estimator__C': [0.01, 0.1, 1, 10, 100],\n",
    "    'ensemble__n_estimators': [10, 50, 100]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(estimator=bbc_pipeline, param_grid=param_grid, scoring='accuracy', cv=5)\n",
    "grid_search.fit(X_res, y_res)\n",
    "\n",
    "# Best parameters and best score\n",
    "best_params = grid_search.best_params_\n",
    "best_score = grid_search.best_score_\n",
    "\n",
    "print(f'Best Parameters: {best_params}')\n",
    "print(f'Best Score: {best_score}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1b8a3d2a-c2e3-4a55-a30a-89bc78353b0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.99655\n",
      "Confusion Matrix:\n",
      "[[19373    33]\n",
      " [   36   558]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     19406\n",
      "           1       0.94      0.94      0.94       594\n",
      "\n",
      "    accuracy                           1.00     20000\n",
      "   macro avg       0.97      0.97      0.97     20000\n",
      "weighted avg       1.00      1.00      1.00     20000\n",
      "\n",
      "Ensemble Model Accuracy: 0.98385\n",
      "Ensemble Model Confusion Matrix:\n",
      "[[19083   323]\n",
      " [    0   594]]\n",
      "Ensemble Model Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99     19406\n",
      "           1       0.65      1.00      0.79       594\n",
      "\n",
      "    accuracy                           0.98     20000\n",
      "   macro avg       0.82      0.99      0.89     20000\n",
      "weighted avg       0.99      0.98      0.99     20000\n",
      "\n",
      "Best Parameters: {'ensemble__estimator__C': 100, 'ensemble__n_estimators': 10}\n",
      "Best Score: 0.9941818166117231\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.ensemble import BalancedBaggingClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv('creditcard.csv')\n",
    "\n",
    "# Separate features and labels\n",
    "X = data.drop('is_fraud', axis=1)\n",
    "y = data['is_fraud']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Categorical features\n",
    "categorical_features = ['gender', 'transaction_location', 'transaction_type', 'card_present', 'repeat_customer', 'merchant_category', 'previous_fraud', 'device_type', 'internet_access']\n",
    "\n",
    "# Numeric features\n",
    "numeric_features = ['transaction_time', 'transaction_amount', 'age', 'account_balance', 'amount_time_interaction', 'age_balance_interaction']\n",
    "\n",
    "# Preprocessing pipeline for numeric and categorical features\n",
    "numeric_transformer = StandardScaler()\n",
    "categorical_transformer = OneHotEncoder()\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ])\n",
    "\n",
    "# Model pipeline\n",
    "model_pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                                 ('classifier', LogisticRegression(max_iter=1000))])\n",
    "\n",
    "# Train the model\n",
    "model_pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model_pipeline.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "class_report = classification_report(y_test, y_pred)\n",
    "\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print('Confusion Matrix:')\n",
    "print(conf_matrix)\n",
    "print('Classification Report:')\n",
    "print(class_report)\n",
    "\n",
    "# Under-sampling\n",
    "rus = RandomUnderSampler(random_state=42)\n",
    "X_res, y_res = rus.fit_resample(X_train, y_train)\n",
    "\n",
    "# Ensemble technique\n",
    "bbc = BalancedBaggingClassifier(estimator=LogisticRegression(max_iter=1000),\n",
    "                                sampling_strategy='auto',\n",
    "                                replacement=False,\n",
    "                                random_state=42)\n",
    "bbc_pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                               ('ensemble', bbc)])\n",
    "\n",
    "bbc_pipeline.fit(X_res, y_res)\n",
    "\n",
    "# Evaluate ensemble model\n",
    "y_pred_ensemble = bbc_pipeline.predict(X_test)\n",
    "accuracy_ensemble = accuracy_score(y_test, y_pred_ensemble)\n",
    "conf_matrix_ensemble = confusion_matrix(y_test, y_pred_ensemble)\n",
    "class_report_ensemble = classification_report(y_test, y_pred_ensemble)\n",
    "\n",
    "print(f'Ensemble Model Accuracy: {accuracy_ensemble}')\n",
    "print('Ensemble Model Confusion Matrix:')\n",
    "print(conf_matrix_ensemble)\n",
    "print('Ensemble Model Classification Report:')\n",
    "print(class_report_ensemble)\n",
    "\n",
    "# Hyperparameter tuning\n",
    "param_grid = {\n",
    "    'ensemble__estimator__C': [0.01, 0.1, 1, 10, 100],\n",
    "    'ensemble__n_estimators': [10, 50, 100]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(estimator=bbc_pipeline, param_grid=param_grid, scoring='accuracy', cv=5)\n",
    "grid_search.fit(X_res, y_res)\n",
    "\n",
    "# Best parameters and best score\n",
    "best_params = grid_search.best_params_\n",
    "best_score = grid_search.best_score_\n",
    "\n",
    "print(f'Best Parameters: {best_params}')\n",
    "print(f'Best Score: {best_score}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0bafb367-45a8-4822-b5d4-e819184b8f9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.96725\n",
      "Confusion Matrix:\n",
      "[[18798   199]\n",
      " [  456   547]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.98     18997\n",
      "           1       0.73      0.55      0.63      1003\n",
      "\n",
      "    accuracy                           0.97     20000\n",
      "   macro avg       0.85      0.77      0.80     20000\n",
      "weighted avg       0.96      0.97      0.96     20000\n",
      "\n",
      "Ensemble Model Accuracy: 0.91295\n",
      "Ensemble Model Confusion Matrix:\n",
      "[[17309  1688]\n",
      " [   53   950]]\n",
      "Ensemble Model Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.91      0.95     18997\n",
      "           1       0.36      0.95      0.52      1003\n",
      "\n",
      "    accuracy                           0.91     20000\n",
      "   macro avg       0.68      0.93      0.74     20000\n",
      "weighted avg       0.97      0.91      0.93     20000\n",
      "\n",
      "Best Parameters: {'ensemble__estimator__C': 0.1, 'ensemble__n_estimators': 100}\n",
      "Best Score: 0.9293219870679499\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.ensemble import BalancedBaggingClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv('updated_creditcard.csv')\n",
    "\n",
    "# Separate features and labels\n",
    "X = data.drop('is_fraud', axis=1)\n",
    "y = data['is_fraud']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Categorical features\n",
    "categorical_features = ['gender', 'transaction_location', 'transaction_type', 'card_present', 'repeat_customer', 'merchant_category', 'previous_fraud', 'device_type', 'internet_access']\n",
    "\n",
    "# Numeric features\n",
    "numeric_features = ['transaction_time', 'transaction_amount', 'age', 'account_balance', 'amount_time_interaction', 'age_balance_interaction']\n",
    "\n",
    "# Preprocessing pipeline for numeric and categorical features\n",
    "numeric_transformer = StandardScaler()\n",
    "categorical_transformer = OneHotEncoder()\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ])\n",
    "\n",
    "# Model pipeline\n",
    "model_pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                                 ('classifier', LogisticRegression(max_iter=1000))])\n",
    "\n",
    "# Train the model\n",
    "model_pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model_pipeline.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "class_report = classification_report(y_test, y_pred)\n",
    "\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print('Confusion Matrix:')\n",
    "print(conf_matrix)\n",
    "print('Classification Report:')\n",
    "print(class_report)\n",
    "\n",
    "# Under-sampling\n",
    "rus = RandomUnderSampler(random_state=42)\n",
    "X_res, y_res = rus.fit_resample(X_train, y_train)\n",
    "\n",
    "# Ensemble technique\n",
    "bbc = BalancedBaggingClassifier(estimator=LogisticRegression(max_iter=1000),\n",
    "                                sampling_strategy='auto',\n",
    "                                replacement=False,\n",
    "                                random_state=42)\n",
    "bbc_pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                               ('ensemble', bbc)])\n",
    "\n",
    "bbc_pipeline.fit(X_res, y_res)\n",
    "\n",
    "# Evaluate ensemble model\n",
    "y_pred_ensemble = bbc_pipeline.predict(X_test)\n",
    "accuracy_ensemble = accuracy_score(y_test, y_pred_ensemble)\n",
    "conf_matrix_ensemble = confusion_matrix(y_test, y_pred_ensemble)\n",
    "class_report_ensemble = classification_report(y_test, y_pred_ensemble)\n",
    "\n",
    "print(f'Ensemble Model Accuracy: {accuracy_ensemble}')\n",
    "print('Ensemble Model Confusion Matrix:')\n",
    "print(conf_matrix_ensemble)\n",
    "print('Ensemble Model Classification Report:')\n",
    "print(class_report_ensemble)\n",
    "\n",
    "# Hyperparameter tuning\n",
    "param_grid = {\n",
    "    'ensemble__estimator__C': [0.01, 0.1, 1, 10, 100],\n",
    "    'ensemble__n_estimators': [10, 50, 100]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(estimator=bbc_pipeline, param_grid=param_grid, scoring='accuracy', cv=5)\n",
    "grid_search.fit(X_res, y_res)\n",
    "\n",
    "# Best parameters and best score\n",
    "best_params = grid_search.best_params_\n",
    "best_score = grid_search.best_score_\n",
    "\n",
    "print(f'Best Parameters: {best_params}')\n",
    "print(f'Best Score: {best_score}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "501ebeca-ba4d-4e59-8949-f5b1661a0fc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.92\n",
      "Confusion Matrix:\n",
      "[[18306    84]\n",
      " [ 1516    94]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     18390\n",
      "           1       0.53      0.06      0.11      1610\n",
      "\n",
      "    accuracy                           0.92     20000\n",
      "   macro avg       0.73      0.53      0.53     20000\n",
      "weighted avg       0.89      0.92      0.89     20000\n",
      "\n",
      "Ensemble Model Accuracy: 0.7239\n",
      "Ensemble Model Confusion Matrix:\n",
      "[[13265  5125]\n",
      " [  397  1213]]\n",
      "Ensemble Model Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.72      0.83     18390\n",
      "           1       0.19      0.75      0.31      1610\n",
      "\n",
      "    accuracy                           0.72     20000\n",
      "   macro avg       0.58      0.74      0.57     20000\n",
      "weighted avg       0.91      0.72      0.79     20000\n",
      "\n",
      "Best Parameters: {'ensemble__estimator__C': 0.1, 'ensemble__n_estimators': 100}\n",
      "Best Score: 0.7285602503912363\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.ensemble import BalancedBaggingClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv('NUcreditcard.csv')\n",
    "\n",
    "# Separate features and labels\n",
    "X = data.drop('is_fraud', axis=1)\n",
    "y = data['is_fraud']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Categorical features\n",
    "categorical_features = ['gender', 'transaction_location', 'transaction_type', 'card_present', 'repeat_customer', 'merchant_category', 'previous_fraud', 'device_type', 'internet_access']\n",
    "\n",
    "# Numeric features\n",
    "numeric_features = ['transaction_time', 'transaction_amount', 'age', 'account_balance', 'amount_time_interaction', 'age_balance_interaction']\n",
    "\n",
    "# Preprocessing pipeline for numeric and categorical features\n",
    "numeric_transformer = StandardScaler()\n",
    "categorical_transformer = OneHotEncoder()\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ])\n",
    "\n",
    "# Model pipeline\n",
    "model_pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                                 ('classifier', LogisticRegression(max_iter=1000))])\n",
    "\n",
    "# Train the model\n",
    "model_pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model_pipeline.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "class_report = classification_report(y_test, y_pred)\n",
    "\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print('Confusion Matrix:')\n",
    "print(conf_matrix)\n",
    "print('Classification Report:')\n",
    "print(class_report)\n",
    "\n",
    "# Under-sampling\n",
    "rus = RandomUnderSampler(random_state=42)\n",
    "X_res, y_res = rus.fit_resample(X_train, y_train)\n",
    "\n",
    "# Ensemble technique\n",
    "bbc = BalancedBaggingClassifier(estimator=LogisticRegression(max_iter=1000),\n",
    "                                sampling_strategy='auto',\n",
    "                                replacement=False,\n",
    "                                random_state=42)\n",
    "bbc_pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                               ('ensemble', bbc)])\n",
    "\n",
    "bbc_pipeline.fit(X_res, y_res)\n",
    "\n",
    "# Evaluate ensemble model\n",
    "y_pred_ensemble = bbc_pipeline.predict(X_test)\n",
    "accuracy_ensemble = accuracy_score(y_test, y_pred_ensemble)\n",
    "conf_matrix_ensemble = confusion_matrix(y_test, y_pred_ensemble)\n",
    "class_report_ensemble = classification_report(y_test, y_pred_ensemble)\n",
    "\n",
    "print(f'Ensemble Model Accuracy: {accuracy_ensemble}')\n",
    "print('Ensemble Model Confusion Matrix:')\n",
    "print(conf_matrix_ensemble)\n",
    "print('Ensemble Model Classification Report:')\n",
    "print(class_report_ensemble)\n",
    "\n",
    "# Hyperparameter tuning\n",
    "param_grid = {\n",
    "    'ensemble__estimator__C': [0.01, 0.1, 1, 10, 100],\n",
    "    'ensemble__n_estimators': [10, 50, 100]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(estimator=bbc_pipeline, param_grid=param_grid, scoring='accuracy', cv=5)\n",
    "grid_search.fit(X_res, y_res)\n",
    "\n",
    "# Best parameters and best score\n",
    "best_params = grid_search.best_params_\n",
    "best_score = grid_search.best_score_\n",
    "\n",
    "print(f'Best Parameters: {best_params}')\n",
    "print(f'Best Score: {best_score}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f80121e-0e9d-49d9-aae8-3c83ea147b7a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
